import re
import logging
import subprocess
import pandas as pd
from time import time
from nltk import word_tokenize
from random import sample, seed
from senti_score2 import SentiScore

"""
Used to get sentiment of adjectives present in the threads
Uses Finnpos for the labeling
"""


# Give a seed for random
seed(666)
# Set number of samples to use
num_of_samples = 100000
# Regex to remove certain characters
regex = re.compile('[a-z åäö\-_!?,.]')
# Set up logging
logger = logging.getLogger('finnpos_labeler')
logging.basicConfig(format='%(asctime)s %(module)s: %(message)s', level=logging.INFO,
                    datefmt='%H:%M:%S', filename='logs/finnpos_label.log', filemode='w')

def read_random_for_year(year, n) -> [str]:
    """
    Read the non preprocessed data for the given year, and extract a random sample of threads
    :param year: Year to get data for
    :param n: Number of random samples
    :return: Titles, texts, and thread_ids
    """
    start = time()
    logger.info(f'Reading database/s24_{year}.csv')
    df = pd.read_csv(f'database/s24_{year}.csv')
    logger.info(f'Extracting a sample of {n} threads')
    samples = df.iloc[sample(range(0, len(df)), n)]
    titles, texts, thread_ids = samples['title'].values, samples['text'].values, samples['thread_id'].values
    df = None
    logger.info(f'Extraction done, took {time()-start}s')
    return list(map(str, titles)), list(map(str, texts)), thread_ids

def save_thread_ids(ids, year):
    """
    Save the tread_ids of the randomly selected threads
    :param ids: Thread ids to save
    :param year: Year from which the threads were extracted
    :return: Nothing
    """
    logger.info(f'Saving sample thread ids for the year {year}')
    f = open(f'finnpos/{year}_ids.txt', 'w')
    for id in ids:
        f.write(str(id) + '\n')
    f.close()

def write_to_file(titles, texts, year):
    """
    Lowercase, regex, tokenize, and save thread titles and texts one word at a time into a .txt file
    :param titles: List of thread titles
    :param texts: List of thread main texts
    :param year: Year from which the threads are taken from
    :return: Nothing
    """
    logger.info('Parsing the sample threads')
    f = open(f'finnpos/data_{year}.txt', 'w')
    start = time()
    titles = list(map(str.lower, titles))
    texts = list(map(str.lower, texts))
    for i in range(len(titles)):
        titles[i] = ''.join(regex.findall(titles[i]))
        texts[i] = ''.join(regex.findall(texts[i]))
        title_tokes = word_tokenize(titles[i])
        text_tokens = word_tokenize(texts[i])
        for token in title_tokes:
            f.write(token+'\n')
        f.write('\n')
        for token in text_tokens:
            f.write(token+'\n')
        f.write('\n')
    f.close()
    logger.info(f'Done parsing, took: {time()-start}s')

def finnpos(year):
    """
    Use ftb-label on the files generated by write_to_file
    :param year: Year for the file
    :return: Nothing
    """
    start = time()
    cmd = f'cat finnpos/data_{year}.txt | ftb-label > finnpos/finnpos_{year}.txt'
    logger.info(f'Adding finnpos labels to the threads, using cmd: {cmd}')
    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
    process.wait()
    logger.info(f'Processing done, took {time()-start}')

def parse_finnpos(year) -> [str, str]:
    """
    Only keep words that are verbs, nouns or adjectives
    :param year: Year from which the data is from
    :return: [word, verb|noun|adj]
    """
    logger.info(f'Parsing finnpos results for the year {year}')
    input = open(f'finnpos/finnpos_{year}.txt', 'r')
    start = time()
    result = []
    for line in input:
        line = line.split()
        if len(line) > 0:
            word = line[0]
            pos = line[3].split('|')[0].replace('[POS=', '').replace(']', '')
            if pos in ['ADJECTIVE', 'VERB', 'NOUN']:
                result.append([word, pos])
    input.close()
    logger.info(f'Done parsing finnpos results, took {time()-start}s')
    return result

def add_sentiment(senti: SentiScore, labeled: pd.DataFrame) -> [str, str, int, int]:
    """
    Adds sentiment to each word
    :param senti: SentiScore object
    :param labeled: Text labeled with Finnpos
    :return: [word, verb|noun|adj, positive, negative]
    """
    logger.info('Adding sentiment to words')
    words = labeled['word'].values
    sentiments = senti.array_sentiment(words)
    labeled['s_pos'] = sentiments[0]
    labeled['s_neg'] = sentiments[1]
    logger.info('Sentiments added')
    return labeled


if __name__ == '__main__':
    senti = SentiScore('.../SentiStr/SentiStrength.jar', '.../SentiStr/SentiDataFI')
    years = [str(i) for i in range(2009, 2018)]
    for year in years:
        titles, texts, thread_ids = read_random_for_year(year, num_of_samples)
        save_thread_ids(thread_ids, year)
        write_to_file(titles, texts, year)
        finnpos(year)

        result = parse_finnpos(year)
        result = pd.DataFrame(result, columns=['word', 'pos'])
        result = add_sentiment(senti, result)
        logger.info(f'Saving final result to finnpos/labeled_{year}.csv')
        result.to_csv(f'finnpos/labeled_{year}.csv', index=False)

